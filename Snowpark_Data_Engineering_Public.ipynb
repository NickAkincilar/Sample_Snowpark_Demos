{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Mvn0qyNlF7"
      },
      "source": [
        "# Pip Install Snowpark (Requires Python 3.8. This only need to run this once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tVqlAMGIEHTT"
      },
      "outputs": [],
      "source": [
        "!pip install snowflake-snowpark-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G1RE5iPNpfs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ijF-sgJNf-U"
      },
      "source": [
        "# 1. Connect via Snowpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPtS8X-WEsz6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import snowflake.snowpark.functions as f\n",
        "from snowflake.snowpark import Session, DataFrame\n",
        "from snowflake.snowpark.functions import udf, col\n",
        "from snowflake.snowpark.types import IntegerType\n",
        "from snowflake.snowpark.functions import call_udf\n",
        "\n",
        "\n",
        "# <----- Make these changes before running the notebook -------\n",
        "# 1. Change Connection params to match your environment\n",
        "# EDIT <..> items and add your Account, Creds, Warehouse & DB name\n",
        "\n",
        "Warehouse_Name = '<Your_WarehouseName>'\n",
        "DB_NAME = '<Your_DbName>'\n",
        "\n",
        "\n",
        "CONNECTION_PARAMETERS = {\n",
        "    \"host\": \"<YourAccount>.snowflakecomputing.com\",\n",
        "    'account': '<YourAccount>',\n",
        "    'user': '<Your_UserID>',\n",
        "    'password': '<Your_Password>',\n",
        "    'role': 'SYSADMIN',\n",
        "}\n",
        "\n",
        "# --- Finish editing this section before running the code\n",
        "# <----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "print(\"Connecting to Snowflake.....\\n\")\n",
        "session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
        "print(\"Connected Successfully!...\\n\\n\")\n",
        "\n",
        "sql_cmd = \"USE SCHEMA {}.PUBLIC\".format(DB_NAME)\n",
        "session.sql(sql_cmd).collect() \n",
        "\n",
        "sql_cmd = \"USE WAREHOUSE {}\".format(Warehouse_Name)\n",
        "session.sql(sql_cmd).collect() \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Perform Data Engineering Tasks"
      ],
      "metadata": {
        "id": "5oTiIs6fZ_e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# 1 - INCREASE COMPUTE TO 4 COMPUTE NODES\n",
        "print(\"Scale UP compute from XS(1 Node) to MEDIUM(4 Nodes) ..\\n\")\n",
        "\n",
        "sql_cmd = \"ALTER WAREHOUSE {} SET WAREHOUSE_SIZE = 'MEDIUM' WAIT_FOR_COMPLETION = TRUE\".format(Warehouse_Name)\n",
        "session.sql(sql_cmd).collect()  \n",
        "\n",
        "print(\"Completed!...\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# 2 - READ & JOIN 2 LARGE TABLES (600M & 1M rows)\n",
        "print(\"Joining, Aggregating with 2 large tables(600M & 1M rows) & Writing results to new table(80M rows) ..\\n\")\n",
        "dfLineItems = session.table(\"SNOWFLAKE_SAMPLE_DATA.TPCH_SF100.LINEITEM\")  # 600 Million Rows\n",
        "dfSuppliers = session.table(\"SNOWFLAKE_SAMPLE_DATA.TPCH_SF100.SUPPLIER\")  # 1 Million Rows\n",
        "\n",
        "print('Lineitems Table: %s rows' % dfLineItems.count())\n",
        "print('Suppliers Table: %s rows' % dfSuppliers.count())\n",
        "\n",
        "\n",
        "# 3 - JOIN TABLES\n",
        "dfJoinTables = dfLineItems.join(dfSuppliers,\n",
        "                                dfLineItems.col(\"L_SUPPKEY\") == dfSuppliers.col(\"S_SUPPKEY\"))  \n",
        "\n",
        "# 4 - SUMMARIZE THE DATA BY SUPPLIER, PART, SUM, MIN & MAX\n",
        "dfSummary = dfJoinTables.groupBy(\"S_NAME\", \"L_PARTKEY\").agg([\n",
        "    f.sum(\"L_QUANTITY\").alias(\"TOTAL_QTY\"),\n",
        "    f.min(\"L_QUANTITY\").alias(\"MIN_QTY\"),\n",
        "    f.max(\"L_QUANTITY\").alias(\"MAX_QTY\"),\n",
        "])\n"
      ],
      "metadata": {
        "id": "SYxSnthzZ5jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **â†‘ Compute is NOT used** up to this point !!! (Lazy Execution model. Resulting dataframe was not used for any I/O ops )"
      ],
      "metadata": {
        "id": "lEzXAgk-YPzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Storing or Showing results triggers the compute & executes the previous steps."
      ],
      "metadata": {
        "id": "wXkkS0m9aKZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# 5 - WRITE THE RESULTS TO A NEW TABLE (80 Million Rows)\n",
        "# -- This is when all the previous operations are compiled & executed as a single job\n",
        "# -- because dfSummary is being written to a new target table\n",
        "dfSummary.write.mode(\"overwrite\").saveAsTable(\"SALES_SUMMARY\")\n",
        "print(\"Completed!...\\n\\n\")\n",
        "\n",
        "\n",
        "# 6 - QUERY THE RESULTS (80 Million Rows)\n",
        "print(\"Query the results..\\n\")\n",
        "dfSales = session.table(\"SALES_SUMMARY\")\n",
        "dfSales.show()\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Completed!...\\n\\n\")\n",
        "\n",
        "print(\"Scale DOWN compute to XS(1 node)..\\n\")\n",
        "\n",
        "sql_cmd = \"ALTER WAREHOUSE {} SET WAREHOUSE_SIZE = 'XSMALL'\".format(Warehouse_Name)\n",
        "session.sql(sql_cmd).collect()  \n",
        "\n",
        "print(\"Completed!...\\n\")\n",
        "\n",
        "print(\"--- %s seconds to Join, Summarize & Write Results to a new Table --- \\n\" % int(end_time - start_time))\n",
        "print(\"--- %s Rows Written to SALES_SUMMARY table\" % dfSales.count())"
      ],
      "metadata": {
        "id": "mgwwptl1XoZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}