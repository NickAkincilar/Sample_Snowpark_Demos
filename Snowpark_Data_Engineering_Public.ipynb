{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Mvn0qyNlF7"
      },
      "source": [
        "# Install Snowpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tVqlAMGIEHTT"
      },
      "outputs": [],
      "source": [
        "!pip install snowflake-snowpark-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G1RE5iPNpfs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1ijF-sgJNf-U"
      },
      "source": [
        "# Connect to Snowflake via SnowPark (& without PySpark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPtS8X-WEsz6",
        "outputId": "17bc376e-73f5-4db7-8813-6f883df8b573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to Snowflake.....\n",
            "\n",
            "Connected Successfully!...\n",
            "\n",
            "Demo Environment Created \n",
            " Resizing to from XS(1 Node) to LARGE(8 Nodes) ..\n",
            "\n",
            "Completed!...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# --->  REMOVE PYSPARK REFERENCES\n",
        "\n",
        "# import pyspark.sql.functions as f\n",
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.sql.functions import udf,col\n",
        "# from pyspark.sql.types import IntegerType\n",
        "# spark = SparkSession.builder.appName(\"DataEngeering1\").getOrCreate()\n",
        "\n",
        "\n",
        "# <---  REPLACE WITH SNOWPARK REFERENCES (Rest of code is almost identical)\n",
        "\n",
        "import snowflake.snowpark.functions as f\n",
        "from snowflake.snowpark import Session, DataFrame\n",
        "from snowflake.snowpark.functions import udf, col\n",
        "from snowflake.snowpark.types import IntegerType\n",
        "from snowflake.snowpark.functions import call_udf\n",
        "\n",
        "\n",
        "# <----- Make these changes before running the notebook -------\n",
        "# Change Connection params to match your environment\n",
        "# <----------------------------------------------------------------------------\n",
        "\n",
        "Warehouse_Name = 'MY_DEMO_WH'\n",
        "DB_name = 'DEMO_SNOWPARK'\n",
        "Schema_Name = 'Public'\n",
        "\n",
        "CONNECTION_PARAMETER = {\n",
        "    \"host\": \"<YourAccount>.snowflakecomputing.com\",\n",
        "    'account': '<YourAccount>',\n",
        "    'user': '<Your_UserID>',\n",
        "    'password': '<Your_Password>',\n",
        "    'role': 'SYSADMIN',\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Connecting to Snowflake.....\\n\")\n",
        "session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
        "print(\"Connected Successfully!...\\n\")\n",
        "\n",
        "sql_cmd = \"CREATE OR REPLACE WAREHOUSE {} WAREHOUSE_SIZE = 'X-Small' \".format(Warehouse_Name)\n",
        "session.sql(sql_cmd).collect() \n",
        "\n",
        "sql_cmd = \"CREATE OR REPLACE DATABASE {}\".format(DB_name)\n",
        "session.sql(sql_cmd).collect() \n",
        "\n",
        "session.use_database(DB_name)\n",
        "session.use_schema(Schema_Name)\n",
        "session.use_warehouse(Warehouse_Name)\n",
        "\n",
        "\n",
        "# 1 - INCREASE COMPUTE TO 4 NODES\n",
        "print(\"Demo Environment Created \\n Resizing to from XS(1 Node) to LARGE(8 Nodes) ..\\n\")\n",
        "\n",
        "sql_cmd = \"ALTER WAREHOUSE {} SET WAREHOUSE_SIZE = 'LARGE' WAIT_FOR_COMPLETION = TRUE\".format(Warehouse_Name)\n",
        "session.sql(sql_cmd).collect()  \n",
        "\n",
        "print(\"Completed!...\\n\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start Data Engineering Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joining, Aggregating with 2 large tables(600M & 1M rows) & Writing results to new table(80M rows) ..\n",
            "\n",
            "Lineitems Table: 600037902 rows\n",
            "Suppliers Table: 1000000 rows\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 2 - READ & JOIN 2 LARGE TABLES (600M & 1M rows)\n",
        "print(\"Joining, Aggregating with 2 large tables(600M & 1M rows) & Writing results to new table(80M rows) ..\\n\")\n",
        "\n",
        "dfLineItems = session.table(\"SNOWFLAKE_SAMPLE_DATA.TPCH_SF100.LINEITEM\")  # 600 Million Rows\n",
        "dfSuppliers = session.table(\"SNOWFLAKE_SAMPLE_DATA.TPCH_SF100.SUPPLIER\")  # 1 Million Rows\n",
        "\n",
        "print('Lineitems Table: %s rows' % dfLineItems.count())\n",
        "print('Suppliers Table: %s rows' % dfSuppliers.count())\n",
        "\n",
        "# 3 - JOIN TABLES\n",
        "dfJoinTables = dfLineItems.join(dfSuppliers,\n",
        "                                dfLineItems.col(\"L_SUPPKEY\") == dfSuppliers.col(\"S_SUPPKEY\"))  \n",
        "\n",
        "# 4 - SUMMARIZE THE DATA BY SUPPLIER, PART, SUM, MIN & MAX\n",
        "dfSummary = dfJoinTables.groupBy(\"S_NAME\", \"L_PARTKEY\").agg([\n",
        "    f.sum(\"L_QUANTITY\").alias(\"TOTAL_QTY\"),\n",
        "    f.min(\"L_QUANTITY\").alias(\"MIN_QTY\"),\n",
        "    f.max(\"L_QUANTITY\").alias(\"MAX_QTY\"),\n",
        "])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **â†‘ Compute is NOT used** up to this point. (Lazy Execution Model) !!!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Storing the Results in Table or Showing results triggers the compute & previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target Table Created!...\n",
            "\n",
            "\n",
            "Query the results..\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "|\"S_NAME\"            |\"L_PARTKEY\"  |\"TOTAL_QTY\"  |\"MIN_QTY\"  |\"MAX_QTY\"  |\n",
            "--------------------------------------------------------------------------\n",
            "|Supplier#000146124  |11646101     |331.00       |17.00      |50.00      |\n",
            "|Supplier#000527051  |10277040     |169.00       |4.00       |45.00      |\n",
            "|Supplier#000541796  |6541795      |330.00       |3.00       |50.00      |\n",
            "|Supplier#000512146  |5512145      |238.00       |3.00       |49.00      |\n",
            "|Supplier#000436838  |19686780     |283.00       |3.00       |50.00      |\n",
            "|Supplier#000351952  |11351951     |105.00       |13.00      |32.00      |\n",
            "|Supplier#000438967  |5188961      |163.00       |5.00       |37.00      |\n",
            "|Supplier#000970465  |14220422     |266.00       |7.00       |48.00      |\n",
            "|Supplier#000908398  |3158388      |273.00       |5.00       |48.00      |\n",
            "|Supplier#000205184  |14205183     |221.00       |21.00      |44.00      |\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "Reducing the warehouse to XS..\n",
            "\n",
            "Completed!...\n",
            "\n",
            "--- 16 seconds to Join, Summarize & Write Results to a new Table --- \n",
            "\n",
            "--- 79975543 Rows Written to SALES_SUMMARY table\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# 5 - WRITE THE RESULTS TO A NEW TABLE ( 80 Million Rows)\n",
        "# <-- This is when all the previous operations are compiled & executed as a single job\n",
        "dfSummary.write.mode(\"overwrite\").saveAsTable(\"SALES_SUMMARY\")\n",
        "print(\"Target Table Created!...\\n\\n\")\n",
        "\n",
        "# 6 - QUERY THE RESULTS (80 Million Rows)\n",
        "print(\"Query the results..\\n\")\n",
        "dfSales = session.table(\"SALES_SUMMARY\")\n",
        "dfSales.show()\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "# 7 - SCALE DOWN COMPUTE TO 1 NODE\n",
        "print(\"Reducing the warehouse to XS..\\n\")\n",
        "sql_cmd = \"ALTER WAREHOUSE {} SET WAREHOUSE_SIZE = 'XSMALL'\".format(Warehouse_Name)\n",
        "session.sql(sql_cmd).collect()  \n",
        "\n",
        "print(\"Completed!...\\n\")\n",
        "\n",
        "print(\"--- %s seconds to Join, Summarize & Write Results to a new Table --- \\n\" % int(end_time - start_time))\n",
        "print(\"--- %s Rows Written to SALES_SUMMARY table\" % dfSales.count())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Benefits of Snowpark Over Spark & PySpark**\n",
        "### - **Quick to Migrate** as code is mostly identical & does not require re-learning new language \n",
        "### - **Cheaper** as compute is serverless & runs only when needed.\n",
        "### - **Faster** as all unnecesseary data movement is eliminated = **Less time** using Compute = **Less Cost**\n",
        "### - **Easier to use = Less FTE** as Little to No Maintanence needed for Compute & Storage. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
